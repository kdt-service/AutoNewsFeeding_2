{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d223a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4820d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub category parameter\n",
    "# 사건사고 : 249\n",
    "# 교육 : 250\n",
    "# 노동 : 251\n",
    "# 언론 : 254\n",
    "# 환경 : 252\n",
    "# 인권/복지 : 59b\n",
    "# 식품/의료 : 255\n",
    "# 지역 : 256\n",
    "# 인물 : 276\n",
    "# 사회 일반 : 257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5deaa3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent' : 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "304dd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(soup):\n",
    "    try:\n",
    "        title = soup.find(id='title_area').text\n",
    "    except:\n",
    "        try: \n",
    "            title = soup.find(class_='news_headline').find(class_='title').text\n",
    "        except:\n",
    "            title = soup.find(id='browse_title').text\n",
    "    return title\n",
    "\n",
    "def get_content(soup):\n",
    "    try:\n",
    "        content = soup.find(id='newsct_article').text\n",
    "    except:\n",
    "        try:\n",
    "            content = soup.find(id=\"newsEndContents\").text\n",
    "        except:\n",
    "            content = soup.find(id='articeBody').text\n",
    "    return content\n",
    "\n",
    "def get_writer(soup):\n",
    "    try:\n",
    "        writer = soup.find(class_='media_end_head_journalist_name').text\n",
    "    except:\n",
    "        try: \n",
    "            writer = soup.find(class_='byline_p').text.strip()\n",
    "        except:\n",
    "            try:\n",
    "                writer = soup.find(class_='byline').text.strip()\n",
    "            except:\n",
    "                writer = 'None'\n",
    "    return writer\n",
    "\n",
    "def get_writed_at(soup):\n",
    "    try:\n",
    "        writed_at = soup.find(class_='media_end_head_info_datestamp_time _ARTICLE_DATE_TIME').text\n",
    "    except:\n",
    "        try:\n",
    "            writed_at = soup.find(class_=\"news_headline\").find(class_='info').find('span').text\n",
    "        except:\n",
    "            writed_at = soup.find(class_='article_info').find('span').find('em').text\n",
    "    return writed_at\n",
    "\n",
    "def get_press(soup):\n",
    "    try:\n",
    "        press = soup.find(class_='media_end_head_top_logo').find('img')['title']\n",
    "    except:\n",
    "        try:\n",
    "            press = soup.find(class_='news_headline').find(class_='logo').find('img')['alt']\n",
    "        except:\n",
    "            press = soup.find(class_='press_logo').find('img')['alt']\n",
    "    return press"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0a4c2c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "20230226 done\n",
      "13\n",
      "20230227 done\n",
      "16\n",
      "20230228 done\n",
      "4\n",
      "20230301 done\n",
      "14\n",
      "20230302 done\n",
      "10\n",
      "20230303 done\n",
      "5\n",
      "20230304 done\n",
      "5\n",
      "20230305 done\n",
      "10\n",
      "20230306 done\n",
      "10\n",
      "20230307 done\n",
      "18\n",
      "20230308 done\n",
      "14\n",
      "20230309 done\n",
      "8\n",
      "20230310 done\n",
      "3\n",
      "20230311 done\n",
      "4\n",
      "20230312 done\n",
      "9\n",
      "20230313 done\n",
      "13\n",
      "20230314 done\n",
      "16\n",
      "20230315 done\n",
      "8\n",
      "20230316 done\n",
      "7\n",
      "20230317 done\n",
      "3\n",
      "20230318 done\n",
      "5\n",
      "20230319 done\n",
      "17\n",
      "20230320 done\n",
      "10\n",
      "20230321 done\n",
      "15\n",
      "20230322 done\n",
      "15\n",
      "20230323 done\n",
      "8\n",
      "20230324 done\n",
      "2\n",
      "20230325 done\n",
      "3\n",
      "20230326 done\n"
     ]
    }
   ],
   "source": [
    "# 식품/의료\n",
    "\n",
    "# date_list = list(map(str, range(20230201, 20230229))) + list(map(str, range(20230301, 20230327)))\n",
    "# df = pd.DataFrame(columns=['title', 'writer', 'writed_at', 'content', 'press', 'main_category', 'sub_category', 'platform'])\n",
    "# df.to_csv('../data/사회_식품의료.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "for date in date_list:\n",
    "    \n",
    "    BASE_URL = 'https://news.naver.com/main/list.naver?mode=LS2D&sid2=255&sid1=102&mid=shm&date={}'.format(date)\n",
    "    \n",
    "    title_list = []\n",
    "    content_list = []\n",
    "    writer_list = []\n",
    "    writed_at_list = []\n",
    "    press_list = []\n",
    "    \n",
    "    # 날짜별 전체 페이지 개수\n",
    "    page = 1\n",
    "    total_page = 1\n",
    "    while True:\n",
    "        URL = BASE_URL + '&page={}'.format(page)\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if soup.find(class_='next nclicks(fls.page)'):\n",
    "            page += 10\n",
    "            total_page += 10\n",
    "        else:\n",
    "            total_page += len(soup.find(class_='paging').find_all('a'))\n",
    "            break\n",
    "    \n",
    "    print(total_page)\n",
    "\n",
    "    # 날짜별 전체 기사 URL\n",
    "    news_url_list = []\n",
    "    for i in range(1, total_page + 1):\n",
    "        URL = BASE_URL + '&page={}'.format(i)\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        for news in soup.find(class_='content').find_all('li'):\n",
    "            news_url_list.append(news.find('a')['href'])\n",
    "    \n",
    "    # 날짜별 기사 정보\n",
    "    for url in news_url_list:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        title = get_title(soup)\n",
    "        content = get_content(soup)\n",
    "        writer = get_writer(soup)\n",
    "        writed_at = get_writed_at(soup)\n",
    "        press = get_press(soup)\n",
    "\n",
    "        title_list.append(title)\n",
    "        content_list.append(content)\n",
    "        writer_list.append(writer)\n",
    "        writed_at_list.append(writed_at)\n",
    "        press_list.append(press)\n",
    "    \n",
    "    # 데이터프레임 저장\n",
    "    df = pd.DataFrame({'title' : title_list,\n",
    "                   'writer' : writer_list,\n",
    "                   'writed_at' : writed_at_list,\n",
    "                   'content' : content_list,\n",
    "                   'press' : press_list})\n",
    "    df['main_category'] = '사회'\n",
    "    df['sub_category'] = '식품/의료'\n",
    "    df['platform'] = 'Naver'\n",
    "    \n",
    "    df.to_csv('../data/사회_식품의료.csv', mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print('{} done'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "e65d33a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 끊긴 날짜 다음날 index 확인\n",
    "date_index = date_list.index('20230214')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "b6dd6b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "2bb3ae0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[688], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m news_url_list:\n\u001b[1;32m     46\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     50\u001b[0m     title \u001b[38;5;241m=\u001b[39m get_title(soup)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 지역\n",
    "\n",
    "# date_list = list(map(str, range(20230201, 20230229))) + list(map(str, range(20230301, 20230327)))\n",
    "# df = pd.DataFrame(columns=['title', 'writer', 'writed_at', 'content', 'press', 'main_category', 'sub_category', 'platform'])\n",
    "# df.to_csv('../data/사회_지역.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "for date in date_list[13:]:\n",
    "    \n",
    "    BASE_URL = 'https://news.naver.com/main/list.naver?mode=LS2D&sid2=256&sid1=102&mid=shm&date={}'.format(date)\n",
    "    \n",
    "    title_list = []\n",
    "    content_list = []\n",
    "    writer_list = []\n",
    "    writed_at_list = []\n",
    "    press_list = []\n",
    "    \n",
    "    # 날짜별 전체 페이지 개수\n",
    "    page = 1\n",
    "    total_page = 0\n",
    "    while True:\n",
    "        URL = BASE_URL + '&page={}'.format(page)\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        if soup.find(class_='next nclicks(fls.page)'):\n",
    "            page += 10\n",
    "            total_page += 10\n",
    "        else:\n",
    "            total_page += len(soup.find(class_='paging').find_all('a'))\n",
    "            break\n",
    "    \n",
    "    print(total_page)\n",
    "\n",
    "    # 날짜별 전체 기사 URL\n",
    "    news_url_list = []\n",
    "    for i in range(1, total_page + 1):\n",
    "        URL = BASE_URL + '&page={}'.format(i)\n",
    "        response = requests.get(URL, headers=headers)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(response.text,'html.parser')\n",
    "        for news in soup.find(class_='content').find_all('li'):\n",
    "            news_url_list.append(news.find('a')['href'])\n",
    "    \n",
    "    # 날짜별 기사 정보\n",
    "    for url in news_url_list:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        title = get_title(soup)\n",
    "        content = get_content(soup)\n",
    "        writer = get_writer(soup)\n",
    "        writed_at = get_writed_at(soup)\n",
    "        press = get_press(soup)\n",
    "\n",
    "        title_list.append(title)\n",
    "        content_list.append(content)\n",
    "        writer_list.append(writer)\n",
    "        writed_at_list.append(writed_at)\n",
    "        press_list.append(press)\n",
    "    \n",
    "    # 데이터프레임 저장\n",
    "    df = pd.DataFrame({'title' : title_list,\n",
    "                   'writer' : writer_list,\n",
    "                   'writed_at' : writed_at_list,\n",
    "                   'content' : content_list,\n",
    "                   'press' : press_list})\n",
    "    df['main_category'] = '사회'\n",
    "    df['sub_category'] = '지역'\n",
    "    df['platform'] = '네이버'\n",
    "    \n",
    "    df.to_csv('../data/사회_지역.csv', mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print('{} done'.format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "b0fbea60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "# dataframe으로 만들기 전 list 길이가 동일한지 확인\n",
    "\n",
    "print(len(title_list))\n",
    "print(len(writer_list))\n",
    "print(len(writed_at_list))\n",
    "print(len(content_list))\n",
    "print(len(press_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "c9cdea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe 변환\n",
    "\n",
    "df = pd.DataFrame({'title' : title_list,\n",
    "                   'writer' : writer_list,\n",
    "                   'writed_at' : writed_at_list,\n",
    "                   'content' : content_list,\n",
    "                   'press' : press_list})\n",
    "df['main_category'] = '사회'\n",
    "df['sub_category'] = '지역'\n",
    "df['platform'] = '네이버'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "e4b5ed18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>writer</th>\n",
       "      <th>writed_at</th>\n",
       "      <th>content</th>\n",
       "      <th>press</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>금산 문화·관광·인삼 유럽권 진출 교두보</td>\n",
       "      <td>길효근 기자</td>\n",
       "      <td>2023.02.14. 오후 1:30</td>\n",
       "      <td>\\n\\n금산군-파독산업전사세계총연합회 MOU 체결\\n\\n\\n\\n금산군은 지난 13일...</td>\n",
       "      <td>대전일보</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[포토뉴스]3·1절 건강달리기대회-횡성소방서</td>\n",
       "      <td>유학렬 기자</td>\n",
       "      <td>2023.02.14. 오후 1:30</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n횡성소방서 김숙자 서장을 비롯한 직원, 소방대원들이 14일 소...</td>\n",
       "      <td>강원일보</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>백제역사문화연구원, 감사 결과 '물의를 빚은 A씨' 고발키로</td>\n",
       "      <td>조정호 기자</td>\n",
       "      <td>2023.02.14. 오후 1:30</td>\n",
       "      <td>\\n\\n\\t\\t\\t부여군 출자·출연 기관인 백제역사문화연구원이 2022년 감사 결과...</td>\n",
       "      <td>대전일보</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>곡성군, 전남 최초 ‘초등학생 치과 진료 지원’ 시행</td>\n",
       "      <td>None</td>\n",
       "      <td>2023.02.14. 오후 1:30</td>\n",
       "      <td>\\n\\n-초등학생 전 학년 치과 진료비 지원\\n\\n\\n\\n지난해 12월 곡성군이 곡...</td>\n",
       "      <td>스포츠동아</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>천하람, '겁먹은 개' 발언한 김정재 향해 \"개가 짖어도 기차는 간다'\"</td>\n",
       "      <td>박재형 기자</td>\n",
       "      <td>2023.02.14. 오후 1:30</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n천하람 국민의힘 당대표 후보가 \"누가 '겁 먹은 개'인지는 지...</td>\n",
       "      <td>대구MBC</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>계룡시, 맞춤형 정신건강프로그램 운영…우울증·자살 예방</td>\n",
       "      <td>송원섭 기자</td>\n",
       "      <td>2023.02.14. 오전 11:53</td>\n",
       "      <td>\\n\\n아동·청소년, 중증정신질환자, 65세 이상 어르신 대상\\n\\n\\n\\n계룡보건...</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>눈 사이 비집고 나와 봄소식 전하는 '복수초'</td>\n",
       "      <td>유형재 기자</td>\n",
       "      <td>2023.02.14. 오전 11:53</td>\n",
       "      <td>\\n\\n봄의 전령사…꽃말은 영원한 행복\\n\\n\\n\\n눈을 이불 삼은 복수초(강릉=연...</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>익산시, 산·학·관 기반 자율주행 실증도시 도약 '시동'</td>\n",
       "      <td>홍인철(ichong@yna.co.kr)</td>\n",
       "      <td>2023.02.14. 오전 11:53</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n자동차 자율주행(CG)[연합뉴스 TV 제공](익산=연합뉴스) ...</td>\n",
       "      <td>연합뉴스</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>단양군, 1급 발암물질 노후 슬레이트 처리비 지원</td>\n",
       "      <td>조영석 기자</td>\n",
       "      <td>2023.02.14. 오전 11:53</td>\n",
       "      <td>\\n\\n215동 대상… 동당 325만원 이내 소규모 주택 우선 지원\\n\\n\\n\\n단...</td>\n",
       "      <td>뉴스1</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>[날씨] 광주·전남 어제보다 기온↓, 평년과 비슷…해안 강풍 주의</td>\n",
       "      <td>KBS 지역국</td>\n",
       "      <td>2023.02.14. 오전 11:52</td>\n",
       "      <td>\\n\\n[KBS 광주]어제에 비해 기온이 다소 내려갔습니다. 아침 기온 광주가 2....</td>\n",
       "      <td>KBS</td>\n",
       "      <td>사회</td>\n",
       "      <td>지역</td>\n",
       "      <td>네이버</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        title                 writer  \\\n",
       "0                      금산 문화·관광·인삼 유럽권 진출 교두보                 길효근 기자   \n",
       "1                    [포토뉴스]3·1절 건강달리기대회-횡성소방서                 유학렬 기자   \n",
       "2           백제역사문화연구원, 감사 결과 '물의를 빚은 A씨' 고발키로                 조정호 기자   \n",
       "3               곡성군, 전남 최초 ‘초등학생 치과 진료 지원’ 시행                   None   \n",
       "4    천하람, '겁먹은 개' 발언한 김정재 향해 \"개가 짖어도 기차는 간다'\"                 박재형 기자   \n",
       "..                                        ...                    ...   \n",
       "241            계룡시, 맞춤형 정신건강프로그램 운영…우울증·자살 예방                 송원섭 기자   \n",
       "242                 눈 사이 비집고 나와 봄소식 전하는 '복수초'                 유형재 기자   \n",
       "243           익산시, 산·학·관 기반 자율주행 실증도시 도약 '시동'  홍인철(ichong@yna.co.kr)   \n",
       "244               단양군, 1급 발암물질 노후 슬레이트 처리비 지원                 조영석 기자   \n",
       "245      [날씨] 광주·전남 어제보다 기온↓, 평년과 비슷…해안 강풍 주의                KBS 지역국   \n",
       "\n",
       "                writed_at                                            content  \\\n",
       "0     2023.02.14. 오후 1:30  \\n\\n금산군-파독산업전사세계총연합회 MOU 체결\\n\\n\\n\\n금산군은 지난 13일...   \n",
       "1     2023.02.14. 오후 1:30  \\n\\n\\n\\n\\n\\n횡성소방서 김숙자 서장을 비롯한 직원, 소방대원들이 14일 소...   \n",
       "2     2023.02.14. 오후 1:30  \\n\\n\\t\\t\\t부여군 출자·출연 기관인 백제역사문화연구원이 2022년 감사 결과...   \n",
       "3     2023.02.14. 오후 1:30  \\n\\n-초등학생 전 학년 치과 진료비 지원\\n\\n\\n\\n지난해 12월 곡성군이 곡...   \n",
       "4     2023.02.14. 오후 1:30  \\n\\n\\n\\n\\n\\n천하람 국민의힘 당대표 후보가 \"누가 '겁 먹은 개'인지는 지...   \n",
       "..                    ...                                                ...   \n",
       "241  2023.02.14. 오전 11:53  \\n\\n아동·청소년, 중증정신질환자, 65세 이상 어르신 대상\\n\\n\\n\\n계룡보건...   \n",
       "242  2023.02.14. 오전 11:53  \\n\\n봄의 전령사…꽃말은 영원한 행복\\n\\n\\n\\n눈을 이불 삼은 복수초(강릉=연...   \n",
       "243  2023.02.14. 오전 11:53  \\n\\n\\n\\n\\n\\n자동차 자율주행(CG)[연합뉴스 TV 제공](익산=연합뉴스) ...   \n",
       "244  2023.02.14. 오전 11:53  \\n\\n215동 대상… 동당 325만원 이내 소규모 주택 우선 지원\\n\\n\\n\\n단...   \n",
       "245  2023.02.14. 오전 11:52  \\n\\n[KBS 광주]어제에 비해 기온이 다소 내려갔습니다. 아침 기온 광주가 2....   \n",
       "\n",
       "     press main_category sub_category platform  \n",
       "0     대전일보            사회           지역      네이버  \n",
       "1     강원일보            사회           지역      네이버  \n",
       "2     대전일보            사회           지역      네이버  \n",
       "3    스포츠동아            사회           지역      네이버  \n",
       "4    대구MBC            사회           지역      네이버  \n",
       "..     ...           ...          ...      ...  \n",
       "241    뉴스1            사회           지역      네이버  \n",
       "242   연합뉴스            사회           지역      네이버  \n",
       "243   연합뉴스            사회           지역      네이버  \n",
       "244    뉴스1            사회           지역      네이버  \n",
       "245    KBS            사회           지역      네이버  \n",
       "\n",
       "[246 rows x 8 columns]"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "17d25b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe 저장\n",
    "df.to_csv('../data/사회_지역.csv', mode='a', header=False, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "fd272c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://n.news.naver.com/mnews/article/079/0003737541?sid=102'"
      ]
     },
     "execution_count": 734,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 url 확인\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "1dc5d173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2932"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 마지막 url index 확인\n",
    "news_url_list.index(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "210c3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list 초기화\n",
    "title_list = []\n",
    "content_list = []\n",
    "writer_list = []\n",
    "writed_at_list = []\n",
    "press_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "c25f943b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 3\u001b[0m, in \u001b[0;36mget_title\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle_area\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 6\u001b[0m, in \u001b[0;36mget_title\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m----> 6\u001b[0m     title \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnews_headline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m(class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[737], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      5\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m title \u001b[38;5;241m=\u001b[39m \u001b[43mget_title\u001b[49m\u001b[43m(\u001b[49m\u001b[43msoup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m content \u001b[38;5;241m=\u001b[39m get_content(soup)\n\u001b[1;32m      9\u001b[0m writer \u001b[38;5;241m=\u001b[39m get_writer(soup)\n",
      "Cell \u001b[0;32mIn[119], line 8\u001b[0m, in \u001b[0;36mget_title\u001b[0;34m(soup)\u001b[0m\n\u001b[1;32m      6\u001b[0m         title \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind(class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews_headline\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfind(class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m         title \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrowse_title\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m title\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# 중단된 url 부터 다시 데이터 수집 시작\n",
    "for url in news_url_list[2932:]: # 마지막 url index\n",
    "    response = requests.get(url, headers=headers)\n",
    "    time.sleep(4)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    title = get_title(soup)\n",
    "    content = get_content(soup)\n",
    "    writer = get_writer(soup)\n",
    "    writed_at = get_writed_at(soup)\n",
    "    press = get_press(soup)\n",
    "\n",
    "    title_list.append(title)\n",
    "    content_list.append(content)\n",
    "    writer_list.append(writer)\n",
    "    writed_at_list.append(writed_at)\n",
    "    press_list.append(press)\n",
    "    \n",
    "# 데이터프레임 저장\n",
    "df = pd.DataFrame({'title' : title_list,\n",
    "               'writer' : writer_list,\n",
    "               'writed_at' : writed_at_list,\n",
    "               'content' : content_list,\n",
    "               'press' : press_list})\n",
    "df['main_category'] = '사회'\n",
    "df['sub_category'] = '지역'\n",
    "df['platform'] = '네이버'\n",
    "\n",
    "df.to_csv('../data/사회_지역.csv', mode='a', header=False, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print('{} done'.format(date))\n",
    "\n",
    "# 코드 실행이 완료되면 \"한 날짜\"에 해당되는 데이터 수집만 끝난 것이므로,, 다시 위로 올라가서 끊긴 날짜 다음날부터 크롤링하면 됩니다! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0ae74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fd71e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a1ca88f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"ko\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no\" name=\"viewport\">\n",
       "<title>네이버 뉴스</title>\n",
       "<link href=\"https://static-nnews.pstatic.net/css/min/20230324/news.css\" rel=\"stylesheet\"/>\n",
       "<link href=\"https://mimgnews.pstatic.net/image/news/m/2014/favicon/favicon.ico\" rel=\"shortcut icon\" type=\"image/x-icon\">\n",
       "<link href=\"https://ssl.pstatic.net/static.news/image/news/m/2018/favicon/06/android_legacy_xxxhpdi_192x192.png\" rel=\"apple-touch-icon-precomposed\"/>\n",
       "<link href=\"https://ssl.pstatic.net/static.news/image/news/m/2018/favicon/06/android_legacy_hdpi_72X72.png\" rel=\"apple-touch-icon-precomposed\" size=\"72x72\"/>\n",
       "<link href=\"https://ssl.pstatic.net/static.news/image/news/m/2018/favicon/06/android_legacy_xhdpi_96x96.png\" rel=\"apple-touch-icon-precomposed\" size=\"96x96\"/>\n",
       "<link href=\"https://ssl.pstatic.net/static.news/image/news/m/2018/favicon/06/android_legacy_xxhpdi_144x144.png\" rel=\"apple-touch-icon-precomposed\" size=\"144x144\"/>\n",
       "<link href=\"https://ssl.pstatic.net/static.news/image/news/m/2018/favicon/06/android_legacy_xxxhpdi_192x192.png\" rel=\"apple-touch-icon-precomposed\" size=\"192x192\"/>\n",
       "<script>\n",
       "\t\tvar g_ssc = nsc = \"Mnews.v2\";\n",
       "\t\tvar g_default_area = \"art\";\n",
       "\n",
       "\t\tvar svr = \"\";\n",
       "\t\tvar nelo = {\n",
       "\t\t\tsampleNumber : 100,\n",
       "\t\t\tmaxCount : 100,\n",
       "\t\t\tmaxSendMessage : \"로그 전송 최대치 도달\"\n",
       "\t\t};\n",
       "\n",
       "\t\tvar service = {\n",
       "\t\t\tnews: false,\n",
       "\t\t\tentertain: false,\n",
       "\t\t\tsports: false,\n",
       "\t\t\tmnews: true,\n",
       "\t\t\tnewsType: true\n",
       "\t\t};\n",
       "\n",
       "\t\tvar isGreendot = document.cookie.indexOf(\"MM_NEW=1\") > -1;\n",
       "\t\tvar isNewGreendot = document.cookie.indexOf(\"MM_NEW=2\") > -1;\n",
       "\n",
       "\t\tvar newsDomain = \"https://news.naver.com\";\n",
       "\n",
       "\t\tvar gnb_service = \"news\";\n",
       "\t\tvar gnb_logout = encodeURIComponent(location.href);\n",
       "\t\tvar gnb_template = \"gnb_utf8\";\n",
       "\t\tvar gnb_brightness = 3;\n",
       "\n",
       "\t\tvar svt = \"20230329013403.711\";\n",
       "\t</script>\n",
       "<script src=\"https://static-nnews.pstatic.net/js/min/20230324/common.min.js\"></script>\n",
       "</link></meta></head>\n",
       "<body class=\"n_news_mnews n_news_error as_mp_layout\">\n",
       "<div class=\"end_container\">\n",
       "<div class=\"u_skip\"><a href=\"#ct\">본문 바로가기</a></div>\n",
       "<header class=\"as_gnb_mnews\" role=\"banner\">\n",
       "<div class=\"header_inner\">\n",
       "<div class=\"Ngnb\">\n",
       "<div class=\"Ngnb_inner\">\n",
       "<div class=\"Ngnb_both\">\n",
       "<div class=\"Ngnb_left\">\n",
       "<span class=\"Ngnb_logo\"><a class=\"Nlogo_link _LINK\" data-clk=\"gnb.naver\" data-pc-url=\"https://www.naver.com/\" data-url=\"https://m.naver.com/\" href=\"https://m.naver.com/\"><span class=\"Nicon_logo\">NAVER</span></a></span>\n",
       "<div class=\"Ngnb_service\">\n",
       "<h1 class=\"Nservice_item\"><a class=\"_LINK\" data-clk=\"gnb.news\" data-pc-url=\"https://news.naver.com/\" data-url=\"https://m.news.naver.com\" href=\"https://m.news.naver.com\"><span class=\"Nicon_service\">뉴스</span></a></h1>\n",
       "<span class=\"Nservice_subitem\">\n",
       "<a class=\"_LINK\" data-clk=\"gnb.entertain\" data-pc-url=\"https://entertain.naver.com/home\" data-url=\"https://m.entertain.naver.com\" href=\"https://m.entertain.naver.com\">\n",
       "<span class=\"Nicon_family Nicon_entertain\">연예</span>\n",
       "</a>\n",
       "</span>\n",
       "<span class=\"Nservice_subitem\">\n",
       "<a class=\"_LINK\" data-clk=\"gnb.sports\" data-pc-url=\"https://sports.news.naver.com/index\" data-url=\"https://m.sports.naver.com\" href=\"https://m.sports.naver.com\">\n",
       "<span class=\"Nicon_family Nicon_sports\">스포츠</span>\n",
       "</a>\n",
       "</span>\n",
       "<span class=\"Nservice_subitem\">\n",
       "<a data-clk=\"gnb.weather\" href=\"https://weather.naver.com\">\n",
       "<span class=\"Nicon_family Nicon_weather\">날씨</span>\n",
       "</a>\n",
       "</span>\n",
       "<span class=\"Nservice_subitem\">\n",
       "<a data-clk=\"gnb.premium\" href=\"https://contents.premium.naver.com\">\n",
       "<span class=\"Nicon_family Nicon_premium\">프리미엄</span>\n",
       "</a>\n",
       "</span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"Ngnb_right\">\n",
       "<div class=\"Ngnb_group\">\n",
       "<div class=\"gnb_dark_type2\" id=\"gnb\"></div>\n",
       "</div>\n",
       "<div class=\"Ngnb_search _SEARCH_WRAP is_hidden\"></div>\n",
       "<div class=\"Ngnb_tool\">\n",
       "<a class=\"Ntool_button _SEARCH_CONTENT_TOGGLE_BUTTON\" data-clk=\"gnb.scho\" href=\"javascript:;\"><span class=\"Nicon_search\">검색</span></a>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</header>\n",
       "<div class=\"ct_wrap\" id=\"ct_wrap\">\n",
       "<div class=\"ct_scroll_wrapper\">\n",
       "<div class=\"newsct_wrapper _GRID_TEMPLATE_COLUMN _STICKY_CONTENT\">\n",
       "<div class=\"error_msg\" data-status=\"501\" id=\"ct\">\n",
       "<i class=\"erms_icon\"></i>\n",
       "<h1 class=\"erms_h\">페이지를 찾을 수 없습니다.</h1>\n",
       "<p class=\"erms_p\">입력한 주소가 잘못되었거나, 사용이 일시 중단되어<br/>요청한 페이지를 찾을 수 없습니다.<br/>서비스 이용에 불편을 드려 죄송합니다.</p>\n",
       "<div class=\"erms_btns\">\n",
       "<a class=\"erms_btn _BACK\" href=\"#\">이전</a>\n",
       "<a class=\"erms_btn _LINK\" data-pc-url=\"https://news.naver.com\" data-url=\"https://media.naver.com/press\" href=\"https://media.naver.com/press\">언론사별</a>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"outside_area _OUTSIDE_AREA\">\n",
       "<div class=\"outside_area_inner _GRID_TEMPLATE_COLUMN_ASIDE _OUTSIDE_AREA_INNER\"></div>\n",
       "</div>\n",
       "<aside class=\"main_aside _MAIN_ASIDE\">\n",
       "<div class=\"main_aside_inner _MAIN_ASIDE_INNER\">\n",
       "<h3 class=\"blind\">구독</h3>\n",
       "<script class=\"_LAZY_LOADING_IFRAME\" type=\"x-tmpl-mustache\">\n",
       "\t\t\t<iframe class=\"_aside _GRID_TEMPLATE_ASIDE_IFRAME\" src=\"https://news.naver.com/aside\" data-allow-domain=\"https://news.naver.com\" style=\"visibility: hidden;\" frameborder=\"no\" scrolling=\"no\" width=\"100%\"></iframe>\n",
       "\t\t\t</script>\n",
       "</div>\n",
       "</aside>\n",
       "</div>\n",
       "</div>\n",
       "<hr/>\n",
       "<div class=\"u_ft _STICKY_FOOTER\">\n",
       "<div class=\"u_ft_inner\">\n",
       "<a class=\"r_pg_top show _MOVE_TOP\" data-clk=\"fot.top\" href=\"#\" id=\"goTop\" style=\"display:none;\">맨위로</a>\n",
       "<footer role=\"contentinfo\">\n",
       "<p class=\"u_ftlkw\" id=\"u_ftlkw\">\n",
       "<a class=\"u_ftlk _LINK\" data-clk=\"fot.login\" data-pc-url=\"https://nid.naver.com/nidlogin.login\" data-url=\"https://nid.naver.com/nidlogin.login?svctype=262144\" href=\"https://nid.naver.com/nidlogin.login?svctype=262144\">로그인</a>\n",
       "<a class=\"u_ftlk _LINK\" data-clk=\"fot.sitemap\" data-pc-url=\"https://www.naver.com/more.html\" data-url=\"https://m.naver.com/services.html?f=svc.news\" href=\"https://m.naver.com/services.html?f=svc.news\">전체서비스</a>\n",
       "</p>\n",
       "<p class=\"u_cr\">\n",
       "<span class=\"u_ftm\">\n",
       "<span class=\"u_cri u_cri_v1\"><a class=\"u_cra _LINK\" data-pc-url=\"https://news.naver.com/main/ombudsman/index.naver\" data-url=\"https://m.news.naver.com/ombudsman/index\" href=\"https://m.news.naver.com/ombudsman/index\">서비스안내</a></span>\n",
       "<span class=\"u_cri u_cri_v1\"><a class=\"u_cra\" data-clk=\"fot.help\" href=\"https://help.naver.com/alias/news/news_007.naver\">뉴스도움말</a></span>\n",
       "<span class=\"u_cri u_cri_v1\"><a class=\"u_cra\" data-clk=\"fot.report\" href=\"https://help.naver.com/alias/news/news_001.naver\">오류신고</a></span>\n",
       "</span>\n",
       "<span class=\"u_copyright\">본 콘텐츠의 저작권은 제공처 또는 네이버에 있으며, 이를 무단<br/>이용하는 경우 저작권법 등에 따라 법적책임을 질 수 있습니다.</span>\n",
       "<span class=\"u_cri\"><span class=\"copymark\">ⓒ</span> <a class=\"u_cra_v1\" data-clk=\"fot.navercorp\" href=\"https://www.navercorp.com\">NAVER Corp.</a></span>\n",
       "<span class=\"u_cri\"><span class=\"copymark\">ⓒ</span> <a class=\"u_cra_v1\">연합뉴스</a></span>\n",
       "</p>\n",
       "</footer>\n",
       "</div>\n",
       "</div></div>\n",
       "<script src=\"https://static-nnews.pstatic.net/js/min/20230324/library.min.js\"></script>\n",
       "<script src=\"https://static-nnews.pstatic.net/js/min/20230324/error.min.js\"></script>\n",
       "<script type=\"text/javascript\">\n",
       "\twindow.onload = function() {\n",
       "\t\tsetTimeout(function() {\n",
       "\t\t\twindow.scrollTo(0, 1);\n",
       "\t\t}, 100);\n",
       "\n",
       "\t\tif (window.matchMedia(\"(prefers-color-scheme)\").media === \"not all\") {\n",
       "\t\t\t$(\"html\").removeClass(\"DARK_THEME\");\n",
       "\t\t}\n",
       "\t};\n",
       "</script>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
